{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Spark SQL and Spark ML Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Source Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for the project is about mobile money transactions based on a sample of real transactions extracted from one month of financial logs from a mobile money service implemented in an African country. The original logs were provided by a multinational company, who is the provider of the mobile financial service which is currently running in more than 14 countries all around the world.\n",
    "\n",
    "This synthetic dataset is scaled down 1/4 of the original dataset and it is created just for Kaggle.\n",
    "The data comes in a .csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# @hidden_cell\n",
    "# This function is used to setup the access of Spark to your Object Storage. The definition contains your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "def set_hadoop_config_with_credentials_f63cbb38899d47179c49ed4a7cf03ccf(name):\n",
    "    \"\"\"This function sets the Hadoop configuration so it is possible to\n",
    "    access data from Bluemix Object Storage using Spark\"\"\"\n",
    "\n",
    "    prefix = 'fs.swift.service.' + name\n",
    "    hconf = sc._jsc.hadoopConfiguration()\n",
    "    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n",
    "    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n",
    "    hconf.set(prefix + '.tenant', '265dd6d8a99a4549a24ac9574846808d')\n",
    "    hconf.set(prefix + '.username', '886a93bbc2564a539f02a62ed61e1a61')\n",
    "    hconf.set(prefix + '.password', 'h8bjj]J[1DME7LnC')\n",
    "    hconf.setInt(prefix + '.http.port', 8080)\n",
    "    hconf.set(prefix + '.region', 'dallas')\n",
    "    hconf.setBoolean(prefix + '.public', False)\n",
    "\n",
    "# you can choose any name\n",
    "name = 'keystone'\n",
    "set_hadoop_config_with_credentials_f63cbb38899d47179c49ed4a7cf03ccf(name)\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load('swift://ITBSProjectFraudDetection.' + name + '/frauddetectionsmall.csv')\n",
    "df.take(5)\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "We visualize the data to get a better understanding of it. It's important to mention that only the CASH_OUT and TRANSFER payment type are having problems with fraud transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fraud = df.toPandas()\n",
    "f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "fraud.type.value_counts().plot(kind='bar', title=\"Transaction type\", ax=ax, figsize=(8,8))\n",
    "plt.show()\n",
    "plt.figure(0)\n",
    "cond = (fraud['isFraud'] >= 1)\n",
    "taf = fraud[cond].type.value_counts().plot(kind='bar',  title=\"Fraud transactions grouped by type\")\n",
    "plt.show(taf)\n",
    "plt.figure(1)\n",
    "cond2 = (fraud['isFraud'] < 1)\n",
    "taf2 = fraud[cond2].type.value_counts().plot(kind='bar',  title=\"No fraud transactions grouped by type\")\n",
    "plt.show(taf2)\n",
    "fraud.hist(column='isFlaggedFraud', bins=5)\n",
    "plt.show()\n",
    "plt.figure(2)\n",
    "medianprops = dict(linestyle='-', linewidth=2, color='blue')\n",
    "bx1 = fraud[cond2].boxplot(column=['oldbalanceDest', 'newbalanceDest'], by='isFraud', medianprops=medianprops)\n",
    "bx2 = fraud[cond2].boxplot(column=['oldbalanceOrg', 'newbalanceOrig'], by='isFraud', medianprops=medianprops)\n",
    "bx3 = fraud[cond2].boxplot(column=['amount'], by='isFraud', medianprops=medianprops)\n",
    "#bx4 = fraud[cond].boxplot(column=['type'], by='isFraud', medianprops=medianprops)\n",
    "plt.show(bx1)\n",
    "plt.show(bx2)\n",
    "plt.show(bx3)\n",
    "plt.figure(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fraud.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plots\n",
    "Next, we want to find correlations between attributes using scatter plots. It's visible that there are correlations between the attributes 'newbalanceDest' and 'oldbalanceDest' as well as between 'newbalanceOrig' and 'oldbalanceOrg'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(4)\n",
    "sc1 = fraud.plot.scatter(x='oldbalanceDest', y='newbalanceDest')\n",
    "sc2 = fraud.plot.scatter(x='oldbalanceOrg', y='newbalanceOrig')\n",
    "sc1 = fraud.plot.scatter(x='oldbalanceDest', y='oldbalanceOrg')\n",
    "sc2 = fraud.plot.scatter(x='oldbalanceOrg', y='newbalanceDest')\n",
    "sc3 = fraud.plot.scatter(x='amount', y='isFraud')\n",
    "sc4 = fraud.plot.scatter(x='oldbalanceDest', y='isFraud')\n",
    "sc5 = fraud.plot.scatter(x='newbalanceDest', y='isFraud')\n",
    "sc6 = fraud.plot.scatter(x='oldbalanceOrg', y='isFraud')\n",
    "sc7 = fraud.plot.scatter(x='newbalanceOrig', y='isFraud')\n",
    "plt.show(sc1)\n",
    "plt.show(sc2)\n",
    "plt.show(sc3)\n",
    "plt.show(sc4)\n",
    "plt.show(sc5)\n",
    "plt.show(sc6)\n",
    "plt.show(sc7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear the data\n",
    "In the next step, we will select the columns that are useful for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df.select(\"type\", \"amount\", \"oldbalanceOrg\", \"newbalanceOrig\", \"oldbalanceDest\", \"newbalanceDest\", (col(\"isFraud\").cast(\"Int\").alias(\"label\")))\n",
    "df2.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "In the next step we split the data in a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splits = df2.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
    "train_rows = train.count()\n",
    "test_rows = test.count()\n",
    "print \"Training Rows:\", train_rows, \" Testing Rows:\", test_rows\n",
    "train.show(5)\n",
    "test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a pipeline and train the model\n",
    "We need to prepare the features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strIdx = StringIndexer(inputCol = \"type\", outputCol = \"typeCat\")\n",
    "labelIdx = StringIndexer(inputCol = \"label\", outputCol = \"idxLabel\")\n",
    "# number is meaningful so that it should be number features\n",
    "catVect = VectorAssembler(inputCols = [\"typeCat\"], outputCol=\"catFeatures\")\n",
    "catIdx = VectorIndexer(inputCol = catVect.getOutputCol(), outputCol = \"idxCatFeatures\")\n",
    "numVect = VectorAssembler(inputCols = [\"amount\", \"oldbalanceOrg\", \"newbalanceOrig\", \"oldbalanceDest\", \"newbalanceDest\"], outputCol=\"numFeatures\")\n",
    "# number vector is normalized\n",
    "minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol=\"normFeatures\")\n",
    "featVect = VectorAssembler(inputCols=[\"idxCatFeatures\", \"normFeatures\"], outputCol=\"features\")\n",
    "\n",
    "cl = []\n",
    "pipeline = []\n",
    "\n",
    "\n",
    "cl.insert(0, DecisionTreeClassifier(labelCol=\"idxLabel\", featuresCol=\"features\"))\n",
    "cl.insert(1, RandomForestClassifier(labelCol=\"idxLabel\", featuresCol=\"features\"))\n",
    "cl.insert(2, LogisticRegression(labelCol=\"idxLabel\", featuresCol=\"features\"))\n",
    "\n",
    "\n",
    "# Pipeline process the series of transformation above, which is 7 transformation\n",
    "for i in range(3):\n",
    "    pipeline.insert(i, Pipeline(stages=[strIdx, labelIdx, catVect, catIdx, numVect, minMax, featVect, cl[i]]))\n",
    "    #piplineModel = pipeline.fit(train)\n",
    "print \"Pipeline complete!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = []\n",
    "\n",
    "#When using the whole dataset, please use the TrainValidationSplit instead of the CrossValidator!\n",
    "\n",
    "paramGrid = (ParamGridBuilder().addGrid(cl[0].impurity, (\"gini\", \"entropy\")).addGrid(cl[0].maxDepth, [5, 10, 20]).addGrid(cl[0].maxBins, [5, 10, 20]).build())\n",
    "cv = CrossValidator(estimator=pipeline[0], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, numFolds=5)\n",
    "#cv = TrainValidationSplit(estimator=pipeline[0], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)\n",
    "model.insert(0, cv.fit(train))\n",
    "print \"Model 1 completed\"\n",
    "\n",
    "\n",
    "paramGrid2 = (ParamGridBuilder().addGrid(cl[1].impurity, (\"gini\", \"entropy\")).addGrid(cl[1].maxDepth, [5, 10, 20]).addGrid(cl[1].maxBins, [5, 10, 20]).build())\n",
    "cv2 = CrossValidator(estimator=pipeline[1], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid2, numFolds=5)\n",
    "#cv2 = TrainValidationSplit(estimator=pipeline[1], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid2, trainRatio=0.8)\n",
    "model.insert(1, cv2.fit(train))\n",
    "print \"Model 2 completed\"\n",
    "\n",
    "paramGrid3 = (ParamGridBuilder().addGrid(cl[2].regParam, [0.01, 0.5, 2.0]).addGrid(cl[2].threshold, [0.30, 0.35, 0.5]).addGrid(cl[2].maxIter, [1, 5]).addGrid(cl[2].elasticNetParam, [0.0, 0.5, 1]).build())\n",
    "cv3 = CrossValidator(estimator=pipeline[2], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid3, numFolds=5)\n",
    "#cv3 = TrainValidationSplit(estimator=pipeline[2], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)\n",
    "model.insert(2, cv3.fit(train))\n",
    "print \"Model 3 completed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "We transform the test dataframe to generate label predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''predictions = model.transform(test)\n",
    "predicted = predictions.select(\"features\", \"prediction\", \"probability\", \"trueLabel\")\n",
    "predicted.show(100, truncate=False)\n",
    "for row in predicted.collect():\n",
    "    print row'''\n",
    "prediction = [] \n",
    "predicted = []\n",
    "for i in range(3):\n",
    "  prediction.insert(i, model[i].transform(test))\n",
    "  predicted.insert(i, prediction[i].select(\"features\", \"prediction\", \"probability\", \"trueLabel\"))\n",
    "  predicted[i].show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "In the next step we evaluate the model. THe most important metric here is the recall, since it is indicating how good we are in detecting fraud transactions when the transaction is actually a fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"trueLabel\", rawPredictionCol=\"prediction\")\n",
    "for i in range(3):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #evaluator = MulticlassClassificationEvaluator(\n",
    "    #labelCol=\"trueLabel\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "    areUPR = evaluator.evaluate(predicted[i], {evaluator.metricName: \"areaUnderPR\"})\n",
    "    areUROC = evaluator.evaluate(predicted[i], {evaluator.metricName: \"areaUnderROC\"})\n",
    "    print(\"AreaUnderPR = %g \" % (areUPR))\n",
    "    print(\"AreaUnderROC = %g \" % (areUROC))\n",
    "\n",
    "    tp = float(predicted[i].filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "    fp = float(predicted[i].filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "    tn = float(predicted[i].filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "    fn = float(predicted[i].filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(\"Precision = %g \" % (precision))\n",
    "    print(\"Recall = %g \" % (recall))\n",
    "\n",
    "    metrics = sqlContext.createDataFrame([\n",
    "    (\"TP\", tp),\n",
    "    (\"FP\", fp),\n",
    "    (\"TN\", tn),\n",
    "    (\"FN\", fn),\n",
    "    (\"Precision\", tp / (tp + fp)),\n",
    "    (\"Recall\", tp / (tp + fn))],[\"metric\", \"value\"])\n",
    "    metrics.show()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.1",
   "language": "python",
   "name": "python2-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}